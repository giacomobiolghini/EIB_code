{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: comtradeapicall in u:\\users\\biolghin\\appdata\\roaming\\python\\python311\\site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install comtradeapicall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "from pandas import json_normalize\n",
    "import urllib3\n",
    "import json\n",
    "import comtradeapicall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = {\n",
    "    'http': 'SECRET',\n",
    "    'https': 'SECRET/'\n",
    "}\n",
    "proxy_url = proxies.get('http') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key\n",
    "subscription_key = 'SECRET'\n",
    "\n",
    "# Where do you want to save?\n",
    "directory = '' #'SECRET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulkDownloadFile(subscription_key, directory, tradeDataType, typeCode, freqCode, clCode, period, reporterCode,\n",
    "                     decompress, publishedDateFrom=None, publishedDateTo=None, proxy_url=proxy_url):\n",
    "\n",
    "    if tradeDataType == 'TARIFFLINE':\n",
    "        baseURLDataAvailability = 'https://comtradeapi.un.org/bulk/v1/getTariffline/' + \\\n",
    "            typeCode + '/' + freqCode + '/' + clCode\n",
    "        prefixFile = 'TARIFFLINE'\n",
    "    elif tradeDataType == \"FINALCLASSIC\":\n",
    "        baseURLDataAvailability = 'https://comtradeapi.un.org/bulk/v1/getClassic/' + \\\n",
    "            typeCode + '/' + freqCode + '/' + clCode\n",
    "        prefixFile = 'FINALCLASSIC'\n",
    "    else:\n",
    "        baseURLDataAvailability = 'https://comtradeapi.un.org/bulk/v1/get/' + \\\n",
    "            typeCode + '/' + freqCode + '/' + clCode\n",
    "        prefixFile = 'FINAL'\n",
    "\n",
    "    PARAMS = dict(reportercode=reporterCode, period=period,\n",
    "                  publishedDateFrom=publishedDateFrom, publishedDateTo=publishedDateTo)\n",
    "    # add key\n",
    "    PARAMS[\"subscription-key\"] = subscription_key\n",
    "    fields = dict(filter(lambda item: item[1] is not None, PARAMS.items()))\n",
    "    if proxy_url:\n",
    "        http = urllib3.ProxyManager(proxy_url=proxy_url)\n",
    "    else:\n",
    "        http = urllib3.PoolManager()\n",
    "    try:\n",
    "        resp = http.request(\"GET\", baseURLDataAvailability,\n",
    "                            fields=fields, timeout=120)\n",
    "        if resp.status != 200:\n",
    "            print(resp.data.decode('utf-8'))\n",
    "        else:\n",
    "            jsonResult = json.loads(resp.data)\n",
    "            if jsonResult['count'] == 0:\n",
    "                print('No data available based on the selection criteria')\n",
    "            else:\n",
    "                # Results contain the required data\n",
    "                df = json_normalize(jsonResult['data'])\n",
    "                totalFiles = df[df.columns[0]].count()\n",
    "                i = 0\n",
    "                while i < totalFiles:\n",
    "                    # prepare file name\n",
    "                    if tradeDataType == 'TARIFFLINE':\n",
    "                        if (df.timestamp[i] is None):\n",
    "                            timestamp = '1900-01-01'\n",
    "                        else:\n",
    "                            timestamp = df.timestamp[i][:10]\n",
    "                        fileName = \"COMTRADE-\" + prefixFile + \"-\" + df.typeCode[i] + \"-\" + df.freqCode[i] + \"-\" + str(df.reporterCode[i]).zfill(\n",
    "                            3) + \"-\" + str(df.period[i]) +\"-\" +  df.classificationCode[i] + \".gz\"\n",
    "                    else:\n",
    "                        if (df.publicationDate[i] is None):\n",
    "                            publicationDate = '1900-01-01'\n",
    "                        else:\n",
    "                            publicationDate = df.publicationDate[i][:10]\n",
    "                        fileName = \"COMTRADE-\" + prefixFile + \"-\" + df.typeCode[i] +\"-\" + df.freqCode[i] + \"-\" + str(\n",
    "                            df.reporterCode[i]).zfill(\n",
    "                            3) + \"-\" + str(df.period[i]) + \"-\" + df.classificationCode[i] + \".gz\"\n",
    "                    download_path = os.path.join(directory, fileName)\n",
    "                    # download file\n",
    "                    file_url = df.fileUrl[i]\n",
    "                    PARAMS = dict()\n",
    "                    PARAMS[\"subscription-key\"] = subscription_key\n",
    "                    fieldsFILE = dict(\n",
    "                        filter(lambda item: item[1] is not None, PARAMS.items()))\n",
    "                    if proxy_url:\n",
    "                        httpFILE = urllib3.ProxyManager(proxy_url=proxy_url)\n",
    "                    else:\n",
    "                        httpFILE = urllib3.PoolManager()\n",
    "                    with open(download_path, 'wb') as out:\n",
    "                        r = httpFILE.request(\n",
    "                            'GET', file_url, fields=fieldsFILE, preload_content=False)\n",
    "                        shutil.copyfileobj(r, out)\n",
    "                    r.release_conn()\n",
    "                    print(fileName.replace(\".gz\", \"\") + ' downloaded')\n",
    "                    download_path_gunzip = download_path.replace(\".gz\", \".txt\")\n",
    "                    if decompress is True:\n",
    "                        with gzip.open(download_path, \"rb\") as f_in:\n",
    "                            with open(download_path_gunzip, 'wb') as f_out:\n",
    "                                shutil.copyfileobj(f_in, f_out)\n",
    "                        os.remove(download_path)\n",
    "                    i = i + 1\n",
    "                print('Total of ' + str(i) + ' file(s) downloaded')\n",
    "    except urllib3.exceptions.RequestError as err:\n",
    "        print(f'Request error: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EIB_bulkDownloadFinalFile(subscription_key, directory, typeCode, freqCode, clCode, period=None, reporterCode=None, decompress=False, publishedDateFrom=None, publishedDateTo=None):\n",
    "    bulkDownloadFile(subscription_key, directory, 'FINAL', typeCode, freqCode, clCode, period,\n",
    "                     reporterCode, decompress, publishedDateFrom, publishedDateTo)\n",
    "\n",
    "\n",
    "def EIB_bulkDownloadFinalClassicFile(subscription_key, directory, typeCode, freqCode, clCode, period=None, reporterCode=None, decompress=False, publishedDateFrom=None, publishedDateTo=None):\n",
    "    bulkDownloadFile(subscription_key, directory, 'FINALCLASSIC', typeCode, freqCode, clCode, period,\n",
    "                     reporterCode, decompress, publishedDateFrom, publishedDateTo)\n",
    "\n",
    "\n",
    "def EIB_bulkDownloadTarifflineFile(subscription_key, directory, typeCode, freqCode, clCode, period=None, reporterCode=None, decompress=False, publishedDateFrom=None, publishedDateTo=None):\n",
    "    bulkDownloadFile(subscription_key, directory, 'TARIFFLINE', typeCode, freqCode, clCode, period,\n",
    "                     reporterCode, decompress, publishedDateFrom, publishedDateTo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mydf=EIB_bulkDownloadFinalClassicFile(subscription_key, directory, typeCode='C', freqCode='A', clCode='HS',\n",
    "                                      period='2020', reporterCode=None, decompress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mydf = EIB_bulkDownloadFinalClassicFile(subscription_key, directory,typeCode='C', freqCode='A', clCode='HS',\n",
    "                                  #      period='2023', reporterCode='380', partnerCode = '0', decompress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter='\\t')\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = 'COMTRADE-FINALCLASSIC-C-A-380-2023-H6.txt'\n",
    "\n",
    "# Read the text file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "def getPreviewData(subscription_key, tradeDataType, typeCode, freqCode, clCode, period, reporterCode, cmdCode,\n",
    "                   flowCode,\n",
    "                   partnerCode,\n",
    "                   partner2Code, customsCode, motCode, maxRecords, format_output, aggregateBy,\n",
    "                   breakdownMode,\n",
    "                   countOnly, includeDesc, proxy_url=proxy_url):\n",
    "    if subscription_key is not None:\n",
    "        if tradeDataType == 'TARIFFLINE':\n",
    "            baseURL = 'https://comtradeapi.un.org/data/v1/getTariffline/' + \\\n",
    "                typeCode + '/' + freqCode + '/' + clCode\n",
    "        else:\n",
    "            baseURL = 'https://comtradeapi.un.org/data/v1/get/' + \\\n",
    "                typeCode + '/' + freqCode + '/' + clCode\n",
    "    else:\n",
    "        if tradeDataType == 'TARIFFLINE':\n",
    "            baseURL = 'https://comtradeapi.un.org/public/v1/previewTariffline/' + \\\n",
    "                typeCode + '/' + freqCode + '/' + clCode\n",
    "        else:\n",
    "            baseURL = 'https://comtradeapi.un.org/public/v1/preview/' + \\\n",
    "                typeCode + '/' + freqCode + '/' + clCode\n",
    "\n",
    "    PARAMS = dict(reportercode=reporterCode, flowCode=flowCode,\n",
    "                  period=period, cmdCode=cmdCode, partnerCode=partnerCode, partner2Code=partner2Code,\n",
    "                  motCode=motCode, customsCode=customsCode,\n",
    "                  maxRecords=maxRecords, format=format_output, aggregateBy=aggregateBy, breakdownMode=breakdownMode,\n",
    "                  countOnly=countOnly, includeDesc=includeDesc)\n",
    "    PARAMS[\"subscription-key\"] = subscription_key\n",
    "    fields = dict(filter(lambda item: item[1] is not None, PARAMS.items()))\n",
    "    if proxy_url:\n",
    "        http = urllib3.ProxyManager(proxy_url=proxy_url)\n",
    "    else:\n",
    "        http = urllib3.PoolManager()\n",
    "    if format_output is None:\n",
    "        format_output = 'JSON'\n",
    "    if format_output != 'JSON':\n",
    "        print(\"Only JSON output is supported with this function\")\n",
    "    else:\n",
    "        try:\n",
    "            resp = http.request(\"GET\", baseURL, fields=fields, timeout=120)\n",
    "            if resp.status != 200:\n",
    "                print(resp.data.decode('utf-8'))\n",
    "            else:\n",
    "                jsonResult = json.loads(resp.data)\n",
    "                if countOnly:\n",
    "                    dictCount = dict(count=jsonResult['count'])\n",
    "                    df = pandas.DataFrame([dictCount])\n",
    "                else:\n",
    "                    # Results contain the required data\n",
    "                    df = json_normalize(jsonResult['data'])\n",
    "                return df\n",
    "        except urllib3.exceptions.RequestError as err:\n",
    "            print(f'Request error: {err}')\n",
    "\n",
    "\n",
    "def previewFinalData(typeCode, freqCode, clCode, period, reporterCode, cmdCode, flowCode,\n",
    "                     partnerCode,\n",
    "                     partner2Code, customsCode, motCode, maxRecords=None, format_output=None,\n",
    "                     aggregateBy=None, breakdownMode=None, countOnly=None, includeDesc=None, proxy_url=proxy_url):\n",
    "    return getPreviewData(None, 'FINAL', typeCode, freqCode, clCode, period, reporterCode,\n",
    "                          cmdCode, flowCode,\n",
    "                          partnerCode,\n",
    "                          partner2Code, customsCode, motCode, maxRecords, format_output, aggregateBy,\n",
    "                          breakdownMode,\n",
    "                          countOnly, includeDesc, proxy_url)\n",
    "\n",
    "\n",
    "def _previewFinalData(typeCode, freqCode, clCode, period, reporterCode, cmdCode, flowCode,\n",
    "                      partnerCode,\n",
    "                      partner2Code, customsCode, motCode, maxRecords=None, format_output=None,\n",
    "                      aggregateBy=None, breakdownMode=None, countOnly=None, includeDesc=None, proxy_url=proxy_url):\n",
    "    main_df = pandas.DataFrame()\n",
    "    for single_period in list(period.split(\",\")):\n",
    "        try:\n",
    "            staging_df = previewFinalData(typeCode, freqCode, clCode, single_period, reporterCode, cmdCode, flowCode,\n",
    "                                          partnerCode,\n",
    "                                          partner2Code, customsCode, motCode, maxRecords, format_output, aggregateBy,\n",
    "                                          breakdownMode,\n",
    "                                          countOnly, includeDesc, proxy_url)\n",
    "        except:  # retry once more after 10 secs  # noqa: E722\n",
    "            print('Repeating API call for period: ' + single_period)\n",
    "            t.sleep(10)\n",
    "            staging_df = previewFinalData(typeCode, freqCode, clCode, single_period, reporterCode, cmdCode, flowCode,\n",
    "                                          partnerCode,\n",
    "                                          partner2Code, customsCode, motCode, maxRecords, format_output, aggregateBy,\n",
    "                                          breakdownMode,\n",
    "                                          countOnly, includeDesc)\n",
    "        main_df = pandas.concat([main_df, staging_df])\n",
    "    return main_df\n",
    "\n",
    "\n",
    "def previewTarifflineData(typeCode, freqCode, clCode, period, reporterCode, cmdCode, flowCode,\n",
    "                          partnerCode,\n",
    "                          partner2Code, customsCode, motCode, maxRecords=None, format_output=None,\n",
    "                          countOnly=None, includeDesc=None, proxy_url=proxy_url):\n",
    "    return getPreviewData(None, 'TARIFFLINE', typeCode, freqCode, clCode, period, reporterCode,\n",
    "                          cmdCode, flowCode,\n",
    "                          partnerCode,\n",
    "                          partner2Code, customsCode, motCode, maxRecords, format_output, None,\n",
    "                          None,\n",
    "                          countOnly, includeDesc, proxy_url)\n",
    "\n",
    "\n",
    "def _previewTarifflineData(typeCode, freqCode, clCode, period, reporterCode, cmdCode, flowCode,\n",
    "                           partnerCode,\n",
    "                           partner2Code, customsCode, motCode, maxRecords=None, format_output=None,\n",
    "                           countOnly=None, includeDesc=None, proxy_url=proxy_url):\n",
    "    main_df = pandas.DataFrame()\n",
    "    for single_period in list(period.split(\",\")):\n",
    "        try:\n",
    "            staging_df = previewTarifflineData(typeCode, freqCode, clCode, single_period, reporterCode, cmdCode,\n",
    "                                               flowCode,\n",
    "                                               partnerCode,\n",
    "                                               partner2Code, customsCode, motCode, maxRecords, format_output,\n",
    "                                               countOnly, includeDesc, proxy_url)\n",
    "        except:  # retry once more after 10 secs  # noqa: E722\n",
    "            print('Repeating API call for period: ' + single_period)\n",
    "            t.sleep(10)\n",
    "            staging_df = previewTarifflineData(typeCode, freqCode, clCode, single_period, reporterCode, cmdCode, flowCode,\n",
    "                                               partnerCode,\n",
    "                                               partner2Code, customsCode, motCode, maxRecords, format_output,\n",
    "                                               countOnly, includeDesc)\n",
    "        main_df = pandas.concat([main_df, staging_df])\n",
    "    return main_df\n",
    "\n",
    "\n",
    "def getFinalData(subscription_key, typeCode, freqCode, clCode, period, reporterCode, cmdCode, flowCode,\n",
    "                 partnerCode,\n",
    "                 partner2Code, customsCode, motCode, maxRecords=None, format_output=None,\n",
    "                 aggregateBy=None, breakdownMode=None, countOnly=None, includeDesc=None, proxy_url=proxy_url):\n",
    "    return getPreviewData(subscription_key, 'FINAL', typeCode, freqCode, clCode, period, reporterCode,\n",
    "                          cmdCode, flowCode,\n",
    "                          partnerCode,\n",
    "                          partner2Code, customsCode, motCode, maxRecords, format_output, aggregateBy,\n",
    "                          breakdownMode,\n",
    "                          countOnly, includeDesc, proxy_url)\n",
    "\n",
    "\n",
    "def _getFinalData(subscription_key, typeCode, freqCode, clCode, period, reporterCode, cmdCode, flowCode,\n",
    "                  partnerCode,\n",
    "                  partner2Code, customsCode, motCode, maxRecords=None, format_output=None,\n",
    "                  aggregateBy=None, breakdownMode=None, countOnly=None, includeDesc=None, proxy_url=proxy_url):\n",
    "    main_df = pandas.DataFrame()\n",
    "    for single_period in list(period.split(\",\")):\n",
    "        try:\n",
    "            staging_df = getFinalData(subscription_key, typeCode, freqCode, clCode, single_period, reporterCode,\n",
    "                                      cmdCode,\n",
    "                                      flowCode, partnerCode,\n",
    "                                      partner2Code, customsCode, motCode, maxRecords, format_output, aggregateBy,\n",
    "                                      breakdownMode,\n",
    "                                      countOnly, includeDesc, proxy_url)\n",
    "        except:  # retry once more after 10 secs  # noqa: E722\n",
    "            print('Repeating API call for period: ' + single_period)\n",
    "            t.sleep(10)\n",
    "            staging_df = getFinalData(subscription_key, typeCode, freqCode, clCode, single_period, reporterCode, cmdCode,\n",
    "                                      flowCode, partnerCode,\n",
    "                                      partner2Code, customsCode, motCode, maxRecords, format_output, aggregateBy,\n",
    "                                      breakdownMode,\n",
    "                                      countOnly, includeDesc, proxy_url)\n",
    "        main_df = pandas.concat([main_df, staging_df])\n",
    "    return main_df\n",
    "\n",
    "\n",
    "def getTarifflineData(subscription_key, typeCode, freqCode, clCode, period, reporterCode, cmdCode, flowCode,\n",
    "                      partnerCode,\n",
    "                      partner2Code, customsCode, motCode, maxRecords=None, format_output=None,\n",
    "                      countOnly=None, includeDesc=None, proxy_url=proxy_url):\n",
    "    return getPreviewData(subscription_key, 'TARIFFLINE', typeCode, freqCode, clCode, period, reporterCode,\n",
    "                          cmdCode, flowCode,\n",
    "                          partnerCode,\n",
    "                          partner2Code, customsCode, motCode, maxRecords, format_output, None,\n",
    "                          None,\n",
    "                          countOnly, includeDesc, proxy_url)\n",
    "\n",
    "\n",
    "def _getTarifflineData(subscription_key, typeCode, freqCode, clCode, period, reporterCode, cmdCode, flowCode,\n",
    "                       partnerCode,\n",
    "                       partner2Code, customsCode, motCode, maxRecords=None, format_output=None,\n",
    "                       countOnly=None, includeDesc=None, proxy_url=proxy_url):\n",
    "    main_df = pandas.DataFrame()\n",
    "    for single_period in list(period.split(\",\")):\n",
    "        try:\n",
    "            staging_df = getTarifflineData(subscription_key, typeCode, freqCode, clCode, single_period, reporterCode,\n",
    "                                           cmdCode, flowCode, partnerCode,\n",
    "                                           partner2Code, customsCode, motCode, maxRecords, format_output,\n",
    "                                           countOnly, includeDesc, proxy_url)\n",
    "        except:  # retry once more after 10 secs  # noqa: E722\n",
    "            print('Repeating API call for period: ' + single_period)\n",
    "            t.sleep(10)\n",
    "            staging_df = getTarifflineData(subscription_key, typeCode, freqCode, clCode, single_period, reporterCode,\n",
    "                                           cmdCode, flowCode, partnerCode,\n",
    "                                           partner2Code, customsCode, motCode, maxRecords, format_output,\n",
    "                                           countOnly, includeDesc, proxy_url)\n",
    "        main_df = pandas.concat([main_df, staging_df])\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the top 4 digits exported commodities\n",
    "#classic breakdown mode will set the partner2Code to World, customsCode to Total, and motCode to Total.\n",
    "df = _getFinalData(subscription_key, typeCode='C', freqCode='A', clCode='HS',period=\"2023\",reporterCode='380',cmdCode='AG2', flowCode=\"X\", partnerCode=0, partner2Code=None, customsCode=None,motCode=None,breakdownMode='classic', includeDesc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677095229000.93"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = df[\"primaryValue\"].sum()\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftot = _getFinalData(subscription_key, typeCode='C', freqCode='A', clCode='HS',period=\"2022\",reporterCode=None,cmdCode='AG2', flowCode=\"X\", partnerCode=0, partner2Code=None, customsCode=None,motCode=None,breakdownMode='classic', includeDesc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2005 has been saved to comtrade_data_2005.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2006 has been saved to comtrade_data_2006.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2007 has been saved to comtrade_data_2007.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2008 has been saved to comtrade_data_2008.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2009 has been saved to comtrade_data_2009.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2010 has been saved to comtrade_data_2010.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2011 has been saved to comtrade_data_2011.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2012 has been saved to comtrade_data_2012.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2013 has been saved to comtrade_data_2013.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2014 has been saved to comtrade_data_2014.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2015 has been saved to comtrade_data_2015.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2016 has been saved to comtrade_data_2016.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2017 has been saved to comtrade_data_2017.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2018 has been saved to comtrade_data_2018.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2019 has been saved to comtrade_data_2019.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2020 has been saved to comtrade_data_2020.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2021 has been saved to comtrade_data_2021.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat(data_frames, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2022 has been saved to comtrade_data_2022.xlsx\n",
      "Data for 2023 has been saved to comtrade_data_2023.xlsx\n"
     ]
    }
   ],
   "source": [
    "reporter_codes = dftot[\"reporterCode\"].unique()\n",
    "years = range(2005, 2024)  # From 2017 to 2023\n",
    "# List to hold all DataFrames\n",
    "\n",
    "for year in years:\n",
    "    data_frames = []\n",
    "\n",
    "    # Loop through reporter codes and download the data\n",
    "    for code in reporter_codes:\n",
    "        df = _getFinalData(subscription_key, typeCode='C', freqCode='A', clCode='HS',period=str(year),reporterCode= code,cmdCode='AG2', flowCode=\"X\", partnerCode=0, partner2Code=None, customsCode=None,motCode=None,breakdownMode='classic', includeDesc=True)\n",
    "        data_frames.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    final_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    final_df.to_excel(f'AG2_comtrade_data_{year}.xlsx', index=False)\n",
    "    \n",
    "    # Optional: Print a confirmation message\n",
    "    print(f'Data for {year} has been saved to comtrade_data_{year}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
